{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down what's likely happening based on the very limited information in the transcript and common practices in backpropagation, even without seeing the actual code.\n",
      "\n",
      "**Understanding the Context**\n",
      "\n",
      "* **'h'**:  This is likely a very terse reference to a specific part of the video lecture.\n",
      "* **`O.grad = 1`**: This is the initialization of the gradient of an output variable `O` to 1. This is common in backpropagation because the gradient of a variable with respect to itself is 1.\n",
      "* **`O._backward()`**: This strongly suggests that `O` is an object in a computational graph (likely implemented as a custom class). The `_backward()` method triggers the backpropagation process.\n",
      "* **\"After executing o._backward how n.grad value gets updated\"**: The core question is how the gradient of another variable `n` is updated as a result of backpropagation initiated from `O`.\n",
      "\n",
      "**How `n.grad` Gets Updated (General Backpropagation Explanation)**\n",
      "\n",
      "The fundamental idea behind backpropagation is the chain rule of calculus.  Here's a simplified explanation of how `n.grad` would be updated if it's involved in the calculation of `O`:\n",
      "\n",
      "1. **Computational Graph:**  Imagine a computational graph, which is a network of operations where each node represents an intermediate variable or computation.\n",
      "\n",
      "2. **Relationship Between `n` and `O`:** The question implies `n` was somehow used as input to calculate `O` (possibly through several intermediate operations). For example:\n",
      "\n",
      "   ```\n",
      "   n -> operation1 -> a -> operation2 -> b -> operation3 -> O \n",
      "   ```\n",
      "\n",
      "3. **`O._backward()`: The Backpropagation Start:** When you call `O._backward()`, it triggers a chain reaction of gradient calculations moving backward through the graph.\n",
      "\n",
      "4. **Chain Rule:** Let's say `O` depends on variable `b`.  Here's how the chain rule would come into play to calculate the gradients:\n",
      "\n",
      "    *   `O.grad` is initialized to 1 (as mentioned in the transcript).\n",
      "    *   During backpropagation, `b.grad` gets updated as  `b.grad = O.grad * derivative of O with respect to b`.\n",
      "    *   The value `b.grad` is stored in `b`.\n",
      "\n",
      "5. **Propagation to `n`:** This continues moving back through the graph. In this simplified scenario:\n",
      "   * The gradient of `a` will be `a.grad = b.grad * derivative of b with respect to a`.\n",
      "   * Eventually, `n.grad` will be calculated: `n.grad = a.grad * derivative of a with respect to n`.\n",
      "\n",
      "6. **Accumulation:** The gradient calculated for a node in the graph could contribute to existing gradient if the node is part of a calculation more than once. `n.grad` could be updated by multiple backpropagation paths. If `n.grad` is updated before from another path, the value will be accumulated.\n",
      "\n",
      "**Why You Might Not See the Code Explicitly Update `n.grad`**\n",
      "\n",
      "The code you're not seeing might have these characteristics:\n",
      "\n",
      "*   **Object-Oriented:**  The `_backward()` method is likely part of a class that has methods or properties to calculate derivatives (e.g., a `Tensor` or `Variable` class common in deep learning libraries).\n",
      "*   **Automatic Differentiation:** The `_backward()` method performs automatic differentiation. It's likely that the class is storing and calculating derivatives for all operations in the computational graph. So, rather than explicit code to update `n.grad`, you might see the methods within the class that implicitly calculate all gradients along all the paths.\n",
      "*   **Recursive Structure:** The `_backward()` method might be calling the `_backward()` of the nodes before it on the graph recursively.\n",
      "* **Gradient Accumulation**: During the backpropagation, the gradient of a node might be updated multiple times by different incoming path. The new gradient will add into current gradient.\n",
      "\n",
      "**Example (Simplified and Hypothetical)**\n",
      "\n",
      "```python\n",
      "class Variable:\n",
      "    def __init__(self, data, _children=()):\n",
      "        self.data = data\n",
      "        self.grad = 0\n",
      "        self._children = _children\n",
      "        self._backward = lambda: None  # Default empty backward function\n",
      "\n",
      "    def __add__(self, other):\n",
      "        out = Variable(self.data + other.data, (self, other))\n",
      "        def _backward():\n",
      "          self.grad += 1.0 * out.grad \n",
      "          other.grad += 1.0 * out.grad\n",
      "        out._backward = _backward\n",
      "        return out\n",
      "\n",
      "    def __mul__(self, other):\n",
      "        out = Variable(self.data * other.data, (self, other))\n",
      "        def _backward():\n",
      "            self.grad += other.data * out.grad\n",
      "            other.grad += self.data * out.grad\n",
      "        out._backward = _backward\n",
      "        return out\n",
      "\n",
      "\n",
      "# Example Usage\n",
      "n = Variable(3.0)\n",
      "w = Variable(2.0)\n",
      "x = n*w\n",
      "o = x + 1\n",
      "\n",
      "o.grad = 1\n",
      "o._backward()\n",
      "\n",
      "print(n.grad) # Output: 2.0\n",
      "```\n",
      "\n",
      "**In Summary**\n",
      "\n",
      "The update of `n.grad` after calling `O._backward()` is happening *implicitly* through:\n",
      "\n",
      "*   The defined chain rule for each operation.\n",
      "*   The recursive way in which the `_backward()` methods trigger calculations backward through the computational graph.\n",
      "*   Gradient accumulation during backpropagation if one node is involved in different paths.\n",
      "\n",
      "The code you're missing likely contains the logic of the custom `Variable` class (or its equivalent) that calculates these derivatives and accumulates gradient values behind the scenes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Use the API key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Select the Gemini Pro model (free tier)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
    "\n",
    "with open(r'sources\\transcripts\\transcript1.txt', 'r') as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "lecture_transcript = transcript[0]\n",
    "\n",
    "question = '''Hi please help me\n",
    "In video I observed when andrej \n",
    "\n",
    "O.grad = 1\n",
    "O._bacward()\n",
    "\n",
    "After executing o._backward how n.grad value gets updated.i did not get that part in code.\n",
    "'''\n",
    "\n",
    "prompt = f\"Here is the lecture transcript: '{lecture_transcript}' Answer the following question based on the provided lecture transcript: '{question}'\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "# image_path = r\"C:\\Users\\hyoil\\Desktop\\qnallm\\image.png\"\n",
    "# with open(image_path, \"rb\") as image_file:\n",
    "#     image_data = image_file.read()\n",
    "# image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# prompt = f\"Here is the lecture transcript: '{lecture_transcript}' Answer the following question based on the provided lecture transcript: '{question}'\"\n",
    "\n",
    "# response = model.generate_content([{'mime_type':'image/jpeg', 'data': image}, prompt])\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_notebook_code(github_url):\n",
    "    \"\"\"Extracts code cells from a Jupyter Notebook on GitHub.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(github_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        notebook_json = json.loads(response.text)\n",
    "        code_cells = []\n",
    "        for cell in notebook_json['cells']:\n",
    "            if cell['cell_type'] == 'code':\n",
    "                source = cell.get('source', [])  # Handle potentially missing 'source'\n",
    "                if isinstance(source, list):     # Check if source is a list\n",
    "                    code_cells.append(\"\".join(source)) # join the list of strings into a single string\n",
    "                elif isinstance(source, str):    # Check if source is a string\n",
    "                    code_cells.append(source)\n",
    "                else:\n",
    "                  print(\"Unexpected source format. Skipping cell\") # handles an unexpected type\n",
    "        return \"\\n\".join(code_cells) #join code cells with newline\n",
    "\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching notebook: {e}\")\n",
    "        return None\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Example (using Andrej Karpathy's notebook, which caused the original issue)\n",
    "github_url = \"https://raw.githubusercontent.com/karpathy/build-nanogpt/refs/heads/master/train_gpt2.py\"\n",
    "code = get_notebook_code(github_url)\n",
    "\n",
    "if code:\n",
    "    with open(\"notebook_code.txt\", \"w\") as f:\n",
    "        f.write(code)\n",
    "    print(\"Code saved to notebook_code.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code saved to colab_code.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_code(notebook_path):\n",
    "    with open(notebook_path, 'r') as f:\n",
    "        notebook = json.load(f)\n",
    "    code_cells = [\n",
    "        \"\".join(cell.get('source', []))\n",
    "        for cell in notebook['cells']\n",
    "        if cell['cell_type'] == 'code'\n",
    "    ]\n",
    "    return \"\\n\".join(code_cells)\n",
    "\n",
    "\n",
    "notebook_path = 'Tokenization.ipynb'\n",
    "code = extract_code(notebook_path)\n",
    "\n",
    "if code:\n",
    "    with open(\"colab_code.txt\", \"w\") as f:\n",
    "        f.write(code)\n",
    "    print(\"Code saved to colab_code.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the multi-line text file\n",
    "with open('lecture9.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Step 2: Strip whitespace from each line and join them into a single string\n",
    "single_line_text = ' '.join(line.strip() for line in text.splitlines() if line.strip())\n",
    "\n",
    "# Step 3: Save the result to a new text file\n",
    "with open('transcript9.txt', 'w') as file:\n",
    "    file.write(single_line_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
